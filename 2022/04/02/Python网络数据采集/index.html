<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Python网络数据采集我最近一时兴起，想学一学爬虫，于是选择了这本书 通过这几天的学习，我的爬虫算是入门了，去网上爬一爬网图应该没有问题 但我暂时不打算继续深入了（后面的知识就比较专业了），这里就记录一下我的学习经过……  思考网络爬虫时通常的想法 通过网站域名获取 HTML 数据 根据目标信息解析数据 存储目标信息 如果有必要，移动到另一个网页重复这个过程   PS:MAC地址MAC（Medi">
<meta property="og:type" content="article">
<meta property="og:title" content="Python网络数据采集">
<meta property="og:url" content="http://example.com/2022/04/02/Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/index.html">
<meta property="og:site_name" content="Pwn进你的心">
<meta property="og:description" content="Python网络数据采集我最近一时兴起，想学一学爬虫，于是选择了这本书 通过这几天的学习，我的爬虫算是入门了，去网上爬一爬网图应该没有问题 但我暂时不打算继续深入了（后面的知识就比较专业了），这里就记录一下我的学习经过……  思考网络爬虫时通常的想法 通过网站域名获取 HTML 数据 根据目标信息解析数据 存储目标信息 如果有必要，移动到另一个网页重复这个过程   PS:MAC地址MAC（Medi">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2022/04/02/Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/1648896145659.png">
<meta property="og:image" content="http://example.com/2022/04/02/Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/1648641134068.png">
<meta property="og:image" content="http://example.com/2022/04/02/Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/1648641183645.png">
<meta property="og:image" content="http://example.com/2022/04/02/Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/1648690984152.png">
<meta property="og:image" content="http://example.com/2022/04/02/Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/1648691319757.png">
<meta property="og:image" content="http://example.com/2022/04/02/Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/1648697579687.png">
<meta property="og:image" content="http://example.com/2022/04/02/Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/1648709275191.png">
<meta property="og:image" content="http://example.com/2022/04/02/Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/1648801080593.png">
<meta property="og:image" content="http://example.com/2022/04/02/Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/1648810074420.png">
<meta property="article:published_time" content="2022-04-02T14:46:35.000Z">
<meta property="article:modified_time" content="2022-04-02T14:53:52.934Z">
<meta property="article:author" content="yhellow">
<meta property="article:tag" content="Crawler">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2022/04/02/Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/1648896145659.png">

<link rel="canonical" href="http://example.com/2022/04/02/Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Python网络数据采集 | Pwn进你的心</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Pwn进你的心</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/04/02/Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="yhellow">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Pwn进你的心">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Python网络数据采集
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2022-04-02 22:46:35 / Modified: 22:53:52" itemprop="dateCreated datePublished" datetime="2022-04-02T22:46:35+08:00">2022-04-02</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Technology/" itemprop="url" rel="index"><span itemprop="name">Technology</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>34k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>31 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="Python网络数据采集"><a href="#Python网络数据采集" class="headerlink" title="Python网络数据采集"></a>Python网络数据采集</h2><p>我最近一时兴起，想学一学爬虫，于是选择了这本书</p>
<p>通过这几天的学习，我的爬虫算是入门了，去网上爬一爬网图应该没有问题</p>
<p>但我暂时不打算继续深入了（后面的知识就比较专业了），这里就记录一下我的学习经过……</p>
<hr>
<h2 id="思考网络爬虫时通常的想法"><a href="#思考网络爬虫时通常的想法" class="headerlink" title="思考网络爬虫时通常的想法"></a>思考网络爬虫时通常的想法</h2><ul>
<li>通过网站域名获取 HTML 数据</li>
<li>根据目标信息解析数据</li>
<li>存储目标信息</li>
<li>如果有必要，移动到另一个网页重复这个过程 </li>
</ul>
<h2 id="PS-MAC地址"><a href="#PS-MAC地址" class="headerlink" title="PS:MAC地址"></a>PS:MAC地址</h2><p>MAC（Media Access Control，介质访问控制），或称为物理地址，MAC位址，硬件位址，用来定义网络设备的位置 </p>
<ul>
<li>第三层网络层负责 IP 地址，第二层数据链路层则负责 MAC 位址</li>
<li>因此一个主机会有一个IP地址，而每个网络位置会有一个专属于它的 MAC 位址 </li>
<li>MAC 地址，用来表示互联网上每一个站点的标识符，采用十六进制数表示，共六个字节(48位)</li>
<li>前三个字节是由 IEEE 的注册管理机构 RA 负责给不同厂家分配的代码(高位24位)，也称为“编制上唯一的标识符”(Organizationally Unique Identifier)</li>
<li>后三个字节(低位24位)由各厂家自行指派给生产的适配器接口，称为扩展标识符(唯一性)</li>
<li>一个地址块可以生成2^24个不同的地址</li>
<li>MAC地址实际上就是适配器地址或适配器标识符EUI-48</li>
</ul>
<p>MAC地址具有唯一性，它是雕在硬件设备上的（不能更改），生产厂家一生产就会把它分配给每个机器</p>
<h2 id="PS-Cookie"><a href="#PS-Cookie" class="headerlink" title="PS:Cookie"></a>PS:Cookie</h2><img src="/2022/04/02/Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/1648896145659.png" class width="1648896145659"> 
<p>Cookie是保存在客户端的纯文本文件（比如txt文件）</p>
<p>所谓的客户端就是我们自己的本地电脑，当我们使用自己的电脑通过浏览器进行访问网页的时候，服务器就会生成一个证书并返回给我的浏览器并写入我们的本地电脑，这个证书就是Cookie</p>
<p>HTTP协议本身是无状态的（即服务器无法判断用户身份），客户端向服务器发起请求，如果服务器需要记录该用户状态，就使用 response 向客户端浏览器颁发一个Cookie，客户端浏览器会把Cookie保存起来，当浏览器再请求该网站时，浏览器把请求的网址连同该Cookie一同提交给服务器（添加到请求头中），服务器检查该Cookie，以此来辨认用户状态</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">属性项</th>
<th style="text-align:left">属性项介绍</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">NAME=VALUE</td>
<td style="text-align:left">键值对，可以设置要保存的 Key/Value，注意这里的 NAME 不能和其他属性项的名字一样</td>
</tr>
<tr>
<td style="text-align:left">Expires</td>
<td style="text-align:left">过期时间，在设置的某个时间点后该 Cookie 就会失效</td>
</tr>
<tr>
<td style="text-align:left">Domain</td>
<td style="text-align:left">生成该 Cookie 的域名，如 domain=”<a target="_blank" rel="noopener" href="http://www.baidu.com">www.baidu.com</a>“</td>
</tr>
<tr>
<td style="text-align:left">Path</td>
<td style="text-align:left">该 Cookie 是在当前的哪个路径下生成的，如 path=/wp-admin/</td>
</tr>
<tr>
<td style="text-align:left">Secure</td>
<td style="text-align:left">如果设置了这个属性，那么只会在 SSH 连接时才会回传该 Cookie</td>
</tr>
</tbody>
</table>
</div>
<h2 id="PS-Session"><a href="#PS-Session" class="headerlink" title="PS:Session"></a>PS:Session</h2><p>Session是服务器为了保存用户状态而创建的一个特殊的对象（Session对象，用于储存特定的用户会话所需的信息）</p>
<p>当浏览器第一次访问服务器时，服务器创建一个 Session对象（该对象有一个唯一的ID，一般称之为SessionID），服务器会将 SessionID 以 Cookie 的方式发送给浏览器，当浏览器再次访问服务器时，会将 SessionID 发送过来，服务器依据 SessionID 就可以找到对应的 Session对象</p>
<p>服务器会向客户发送一个名为 JSESSIONID 的 Cookie ，它的值为该Session的ID，用于判断是否为同一用户</p>
<h2 id="PS-Token"><a href="#PS-Token" class="headerlink" title="PS:Token"></a>PS:Token</h2><p>Token，又称令牌，其实就是一种验证机制（和Cookie-Session效果类似）</p>
<p>用户请求登录时，服务器后端会生成一个 Token 存储于 Redis 数据库中（临时存放），然后把该 Token 返回到前端最终交给客户端，接下来用户再次请求时便会携带 Token 发送给服务器，服务器再去效验 Token 的正确性</p>
<h2 id="网络浏览器-amp-爬虫原理"><a href="#网络浏览器-amp-爬虫原理" class="headerlink" title="网络浏览器&amp;爬虫原理"></a>网络浏览器&amp;爬虫原理</h2><p>网络浏览器是一个非常有用的应用，它创建信息的数据包，发送它们，然后把你获取的数据解释成漂亮的图像、声音、视频和文字</p>
<p>但是，网络浏览器就是代码，而代码是可以分解的，可以分解成许多基本组件，可重写、重用，以及做成我们想要的任何东西</p>
<p><strong>网络浏览器可以让服务器发送一些数据，到那些对接无线（或有线）网络接口的应用上， 但是许多语言也都有实现这些功能的库文件</strong></p>
<p>也就是说，其他的编程语言也可以模仿浏览器的行为，从而向服务器请求数据，这便是网络爬虫的原理</p>
<p>让我们看看 Python 是如何实现的： </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"></span><br><span class="line">html = urlopen(<span class="string">&quot;https://ywhkkx.github.io/&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(html.read())</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\ywx813\anaconda3\python.exe D:/PythonProject/Crawler/test.py</span><br><span class="line">b<span class="number">&#x27;</span>&lt;!DOCTYPE html&gt;\n&lt;html lang=<span class="string">&quot;en&quot;</span>&gt;\n&lt;head&gt;\n  &lt;meta charset=<span class="string">&quot;UTF-8&quot;</span>&gt;\n&lt;meta name=<span class="string">&quot;viewport&quot;</span> content=<span class="string">&quot;width=device-width, initial-scale=......script src=&quot;</span>/js/next-boot.js<span class="string">&quot;&gt;&lt;/script&gt;\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n  \n\n&lt;/body&gt;\n&lt;/html&gt;\n&#x27; </span></span><br></pre></td></tr></table></figure>
<p>这将会输出 <code>https://ywhkkx.github.io/</code> 这个网页的全部 HTML 代码，更准确地说，这会输出在域名为 <code>ywhkkx.github.io</code> 的 github 服务器上文件夹里的 HTML 文件的源代码</p>
<p>现在大多数网页需要加载许多相关的资源文件：可能是图像文件、JavaScript 文件、CSS 文件，或你需要连接的其他各种网页内容</p>
<p>当网络浏览器遇到一个标签时，比如 <code>&lt;img src=&quot;cuteKitten.jpg&quot;&gt;</code> ，会向服务器发起另一个请求，以获取 cuteKitten.jpg 文件中的数据为用户充分渲染网页，但是，我们的 Python 程序没有返回并向服务器请求多个文件的逻辑，它只能读取我们已经请求的单个 HTML 文件，不过 Python 有对付的办法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br></pre></td></tr></table></figure>
<p>urllib 是 Python 的标准库，包含了从网络请求数据，处理 cookie，甚至改变像请求头和用户代理这些元数据的方法</p>
<p>urlopen 用来打开并读取一个从网络获取的远程对象，因为它是一个非常通用的库（它可以轻松读取 HTML 文件、图像文件，或其他任何文件流），所以我们将在本书中频繁地使用它 </p>
<h2 id="BeautifulSoup简介"><a href="#BeautifulSoup简介" class="headerlink" title="BeautifulSoup简介"></a>BeautifulSoup简介</h2><p>BeautifulSoup 尝试化平淡为神奇，它通过定位 HTML 标签来格式化和组织复杂的网络信息，用简单易用的 Python 对象为我们展现 XML 结构信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">html = urlopen(<span class="string">&quot;https://ywhkkx.github.io/&quot;</span>)</span><br><span class="line">bsObj = BeautifulSoup(html.read(),<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(bsObj.h1) <span class="comment"># 这里只要求显示&quot;h1&quot;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\ywx813\anaconda3\python.exe D:/PythonProject/Crawler/test.py</span><br><span class="line">&lt;h1 <span class="class"><span class="keyword">class</span>=</span><span class="string">&quot;site-title&quot;</span>&gt;Pwn进你的心&lt;/h1&gt;</span><br></pre></td></tr></table></figure>
<p>可以发现 BeautifulSoup 把原本的“杂乱无章”变成了“井井有条”</p>
<p>和前面例子一样，我们导入 urlopen，然后调用 html.read() 获取网页的 HTML 内容，这样就可以把 HTML 内容传到 BeautifulSoup 对象，转换成更加易读的结构，其实，任何 HTML（或 XML）文件的任意节点信息都可以被提取出来，只要目标信息的旁边或附近有标记就行</p>
<h2 id="“可靠”的网络连接"><a href="#“可靠”的网络连接" class="headerlink" title="“可靠”的网络连接"></a>“可靠”的网络连接</h2><p>网络是十分复杂的，网页数据格式不友好，网站服务器宕机，目标数据的标签找不到，都是很麻烦的事情</p>
<p>让我们看看爬虫 import 语句后面的第一行代码，如何处理那里可能出现的异常：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">html = urlopen(<span class="string">&quot;https://ywhkkx.github.io/&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>这行代码主要可能会发生两种异常：</p>
<ul>
<li>网页在服务器上不存在（或者获取页面的时候出现错误）</li>
<li>服务器不存在 </li>
</ul>
<p>第一种异常发生时，程序会返回 HTTP 错误，HTTP 错误可能是 “404 Page Not Found” ，“500  Internal Server Error” 等，所有类似情形，urlopen 方法抛出“HTTPError”异常，我们可以用下面的方式处理这种异常：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    html = urlopen(<span class="string">&quot;https://ywhkkx.github.io/&quot;</span>)</span><br><span class="line"><span class="keyword">except</span> HTTPError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e)</span><br><span class="line"><span class="keyword">else</span>:</span><br></pre></td></tr></table></figure>
<p>第一种异常发生时（服务器不存在），urlopen 会返回一个 None 对象，这个对象与其他编程语言中的 null 类似，我们可以增加一个判断语句检测返回的 html 是不是 None</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> html <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;URL is not found&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br></pre></td></tr></table></figure>
<p>当然，即使网页已经从服务器成功获取，如果网页上的内容并非完全是我们期望的那样，仍然可能会出现异常，每当你调用 BeautifulSoup 对象里的一个标签时，增加一个检查条件保证标签确实存在是很聪明的做法</p>
<p>如果你想要调用的标签不存在，BeautifulSoup 就会返回 None 对象，不过，如果再调用这个 None 对象下面的子标签，就会发生 AttributeError 错误</p>
<p>比如下段代码：（nonExistentTag 是虚拟的标签，BeautifulSoup 对象里实际没有） </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(bsObj.nonExistentTag.someTag) </span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AttributeError: <span class="string">&#x27;NoneType&#x27;</span> object has no attribute <span class="string">&#x27;someTag&#x27;</span></span><br></pre></td></tr></table></figure>
<p>那么我们怎么才能避免这两种情形的异常呢？最简单的方式就是对两种情形进行检查： </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    badContent = bsObj.nonExistingTag.anotherTag</span><br><span class="line"><span class="keyword">except</span> AttributeError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Tag was not found&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">if</span> badContent == <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">print</span> (<span class="string">&quot;Tag was not found&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(badContent)</span><br></pre></td></tr></table></figure>
<p>初看这些检查与错误处理的代码会觉得有点儿累赘，但是，我们可以重新简单组织一下代码，让它变得不那么难写（更重要的是，不那么难读），例如，下面的代码是上面爬虫的另一种写法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> urllib.error <span class="keyword">import</span> HTTPError</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getTitle</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        html = urlopen(url) <span class="comment"># 尝试获取html</span></span><br><span class="line">    <span class="keyword">except</span> HTTPError <span class="keyword">as</span> e: <span class="comment"># 如果发生&quot;HTTP错误&quot;则返回None</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span> </span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        bsObj = BeautifulSoup(html.read(),<span class="string">&quot;html.parser&quot;</span>) <span class="comment"># 尝试利用BeautifulSoup解析html</span></span><br><span class="line">        title = bsObj.body.h1</span><br><span class="line">    <span class="keyword">except</span> AttributeError <span class="keyword">as</span> e: <span class="comment"># 如果&quot;没有获取到目标标签&quot;则返回None</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">return</span> title</span><br><span class="line"></span><br><span class="line">title = getTitle(<span class="string">&quot;https://ywhkkx.github.io/&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> title == <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Title could not be found&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(title)</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\ywx813\anaconda3\python.exe D:/PythonProject/Crawler/test.py</span><br><span class="line">&lt;h1 <span class="class"><span class="keyword">class</span>=</span><span class="string">&quot;site-title&quot;</span>&gt;Pwn进你的心&lt;/h1&gt;</span><br></pre></td></tr></table></figure>
<p>在写爬虫的时候，思考代码的总体格局，让代码既可以捕捉异常又容易阅读，这是很重要的，如果你还希望能够很大程度地重用代码，那么拥有像 getSiteHTML 和 getTitle 这样的 通用函数（具有周密的异常处理功能）会让快速稳定地网络数据采集变得简单易行</p>
<h2 id="通过属性查找标签"><a href="#通过属性查找标签" class="headerlink" title="通过属性查找标签"></a>通过属性查找标签</h2><p>每个网站都会有层叠样式表（Cascading Style Sheet，CSS）</p>
<p>CSS 是专门为了让浏览器和人类可以理解网站内容而设计一个展现样式的层，但是 CSS 的发明却是网络爬虫的福音 </p>
<p>CSS 可以让 HTML 元素呈现出差异化，使那些具有完全相同修饰的元素呈现出不同的样式，比如，有一些标签看起来是这样：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="selector-tag">span</span> class=&quot;green&quot;&gt;&lt;/<span class="selector-tag">span</span>&gt;</span><br><span class="line">&lt;<span class="selector-tag">span</span> class=&quot;red&quot;&gt;&lt;/<span class="selector-tag">span</span>&gt;</span><br></pre></td></tr></table></figure>
<p>网络爬虫可以通过 class 属性的值，轻松地区分出两种不同的标签，如果我们想根据 class 属性来爬取需要的内容，就可以用到 findAll 方法</p>
<p>先看看目标网页：<a target="_blank" rel="noopener" href="https://www.pythonscraping.com/pages/warandpeace.html">https://www.pythonscraping.com/pages/warandpeace.html</a></p>
<img src="/2022/04/02/Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/1648641134068.png" class width="1648641134068"> 
<img src="/2022/04/02/Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/1648641183645.png" class width="1648641183645"> 
<p>它的 html 结构很是简单，寻找 class 很是方便，我们可以用以下代码来爬取绿色字体的内容：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">html = urlopen(<span class="string">&quot;https://www.pythonscraping.com/pages/warandpeace.html&quot;</span>)</span><br><span class="line">bsObj = BeautifulSoup(html,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"></span><br><span class="line">namelist = bsObj.findAll(<span class="string">&quot;span&quot;</span>,&#123;<span class="string">&quot;class&quot;</span>:<span class="string">&quot;green&quot;</span>&#125;) <span class="comment"># Python字典 - &#123;&quot;A&quot;:&quot;B&quot;&#125;</span></span><br><span class="line"><span class="keyword">for</span> name <span class="keyword">in</span> namelist:</span><br><span class="line">    <span class="built_in">print</span>(name.get_text()) <span class="comment"># get_text():把你正在处理的HTML文档中所有的标签都清除，返回一个只包含文字的字符串</span></span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\ywx813\anaconda3\python.exe D:/PythonProject/Crawler/test.py</span><br><span class="line">Anna</span><br><span class="line">Pavlovna Scherer</span><br><span class="line">Empress Marya</span><br><span class="line">Fedorovna</span><br><span class="line">Prince Vasili Kuragin</span><br><span class="line">Anna Pavlovna</span><br><span class="line">    ......</span><br></pre></td></tr></table></figure>
<p>BeautifulSoup 里的 find() 和 findAll() 可能是你最常用的两个方法，借助它们，你可以通过标签的不同属性轻松地过滤 HTML 页面，查找需要的标签组或单个标签</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">findAll(tag, attributes, recursive, text, limit, keywords)</span><br><span class="line">find(tag, attributes, recursive, text, keywords)</span><br></pre></td></tr></table></figure>
<ul>
<li>tag：标签参数，可以传一个标签的名称或多个标签名称组成的Python列表做标签参数</li>
<li>attributes：属性参数，用一个Python字典封装一个标签的若干属性和对应的属性值</li>
<li>recursive：递归参数，这是一个布尔变量，设置为True，表示去查找目标标签中所有的子标签，设置为False，表示只查找一级标签（recursive默认为True）</li>
<li>text：文本参数，查找文本的内容（它是用标签的文本内容去匹配，而不是用标签的属性）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nameList = bsObj.findAll(text=<span class="string">&quot;the prince&quot;</span>) <span class="comment"># 查找&quot;the prince&quot;,返回所有的目标</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(nameList)) <span class="comment"># 结果为&quot;7&quot;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>limit：限制参数，只用于 findAll 方法，find 其实等价于 findAll 的 limit 等于 1 时的情形，如果你只对网页中获取的前 x 项结果感兴趣，就可以设置它，但是要注意，这个参数设置之后，获得的前几项结果是按照网页上的顺序排序的，未必是你想要的那前几项 </li>
<li>keyword：关键词参数，让你选择那些具有指定属性的标签（这是一个冗余的参数）</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">allText = bsObj.findAll(id=<span class="string">&quot;text&quot;</span>)</span><br><span class="line">print(allText[<span class="number">0</span>].get_text())</span><br></pre></td></tr></table></figure>
<h2 id="PS-面向对象"><a href="#PS-面向对象" class="headerlink" title="PS:面向对象"></a>PS:面向对象</h2><p>面向对象(Object Oriented)是软件开发方法，一种编程范式，面向对象是一种对现实世界理解和抽象的方法，是计算机编程技术发展到一定阶段后的产物</p>
<p>通过面向对象的方式，将现实世界的事物抽象成对象，现实世界中的关系抽象成类、继承，帮助人们实现对现实世界的抽象与数字建模</p>
<p>面向对象是在结构化设计方法出现很多问题的情况下应运而生的</p>
<p>PS：结构化设计方法求解问题的基本策略是 <strong>从功能的角度审视问题域</strong> ，它将应用程序看成实现某些特定任务的 <strong>功能模块</strong> ，其中子过程是实现某项具体操作的底层功能模块，在每个功能模块中，用 <strong>数据结构描述待处理数据的组织形式，用算法描述具体的操作过程</strong>（把C语言的函数往里面套，可以方便理解）</p>
<p>面向对象的几大要数：</p>
<p>一，审视问题域的视角</p>
<ul>
<li>在现实世界中存在的客体是问题域中的主角（所谓客体是指客观存在的对象实体和主观抽象的概念），在自然界，每个客体都具有一些 <strong>属性和行为</strong> ，因此， <strong>每个个体都可以用属性和行为来描述</strong>（比如：IO_FILE文件系统中，就是用FILE结构体来描述整个文件）</li>
<li>结构化设计方法所采用的设计思路不是将客体作为一个整体，而是将依附于客体之上的行为抽取出来，以功能为目标来设计构造应用系统</li>
</ul>
<p>二，抽象级别</p>
<ul>
<li>抽象主要包括过程抽象和数据抽象（结构化设计方法应用的是过程抽象）</li>
<li>过程抽象：是将问题域中具有明确功能定义的操作抽取出来，并将其作为一个实体看待（比如C语言的函数）</li>
<li>数据抽象：数据抽象是较过程抽象更高级别的抽象方式，将描述客体的属性和行为绑定在一起，实现统一的抽象，从而达到对现实世界客体的真正模拟（说实话，这句话讲的也挺抽象的，不过看看上文中“BeautifulSoup”方法返回的那个“bsObj”，Python支持直接在它的身上使用函数，那么就可以把“bsObj”理解为某种抽象了）</li>
</ul>
<p>三，封装体 </p>
<ul>
<li>封装是指将现实世界中存在的某个客体的属性与行为绑定在一起，并放置在一个逻辑单元内， 该逻辑单元负责将所描述的属性隐藏起来，外界对客体内部属性的所有访问只能通过提供的用户接口实现（还是上文中提及的那个“bsObj”，它就是一个分装体）</li>
<li>结构化设计方法没有做到客体的整体封装，只是封装了各个功能模块，而每个功能模块可以随意地对没有保护能力客体属性实施操作，并且由于描述属性的数据与行为被分割开来，所以一旦某个客体属性的表达方式发生了变化，或某个行为效果发生了改变，就有可能对整个系统产生影响（想想C语言的函数，好像的确是这样）</li>
</ul>
<p>四，可重用性</p>
<ul>
<li>可重用性标识着软件产品的可复用能力，是衡量一个软件产品成功与否的重要标志</li>
</ul>
<p>面向对象的几大概念：</p>
<ul>
<li>对象：对象所指的是计算机系统中的某一个成分，它有两个含义：其中一个是数据，另外一个是动作，可以说对象则是数据和动作的结合体，对象不仅能够进行操作，同时还能够及时记录下操作结果</li>
<li>方法：方法是指对象能够进行的操作（方法同时还有另外一个名称：函数），方法是类中的定义函数，其具体的作用就是对对象进行描述操作</li>
<li>继承：继承简单地说就是一种层次模型，这种层次模型能够被重用，层次结构的上层具有通用性，但是下层结构则具有特殊性，在继承的过程中类则可以从最顶层的部分继承一些方法和变量（继承是从一般演绎到特殊的过程，可以减少知识表示的冗余内容，知识库的维护和修正都非常方便，更有利于衍生复杂的系统）</li>
<li>类：类是具有相同特性（数据元素）和行为（功能）的对象的抽象（因此，对象的抽象是类，类的具体化就是对象，也可以说类的实例是对象），类实际上就是一种数据类型，类具有属性，它是对象的状态的抽象，用数据结构来描述类的属性</li>
<li>封装：封装是将数据和代码捆绑到一起，对象的某些数据和代码可以是私有的，不能被外界访问，以此实现对数据和代码不同级别的访问权限</li>
<li>多态：多态是指不同事物具有不同表现形式的能力，多态机制使具有不同内部结构的对象可以共享相同的外部接口，通过这种方式减少代码的复杂度（一个接口，多种方式）</li>
<li>动态绑定：动态绑定指的是将一个过程调用与相应代码链接起来的行为，动态绑定是指与给定的过程调用相关联的代码只有在运行期才可知的一种绑定，它是多态实现的具体形式</li>
<li>消息传递：对象之间需要相互沟通，沟通的途径就是对象之间收发信息，消息内容包括接收消息的对象的标识，需要调用的函数的标识，以及必要的信息，消息传递的概念使得对现实世界的描述更容易</li>
</ul>
<h2 id="导航树"><a href="#导航树" class="headerlink" title="导航树"></a>导航树</h2><p>HTML 页面可以映射成一棵树 </p>
<p>在 BeautifulSoup 库里，孩子（child）和后代（descendant）有显著的不同：和人类的家谱一样，子标签就是一个父标签的下一级，而后代标签是指一个父标签下面所有级别的标签</p>
<p>一般情况下，BeautifulSoup 函数总是处理当前标签的后代标签（例如，bsObj.body.h1 选择了 body 标签后代里的第一个 h1 标签，不会去找 body 外面的标签）</p>
<p>接下来介绍几个标签处理的方法：</p>
<p><strong>如果你只想找出子标签，可以用 .children</strong>（程序默认选择 .children）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">html = urlopen(<span class="string">&quot;http://www.pythonscraping.com/pages/page3.html&quot;</span>)</span><br><span class="line">bsObj = BeautifulSoup(html,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> child <span class="keyword">in</span> bsObj.find(<span class="string">&quot;table&quot;</span>,&#123;<span class="string">&quot;id&quot;</span>:<span class="string">&quot;giftList&quot;</span>&#125;).children:</span><br><span class="line">    <span class="built_in">print</span>(child)</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\ywx813\anaconda3\python.exe D:/PythonProject/Crawler/test.py</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;tr&gt;&lt;th&gt; <span class="comment">/* 打印&lt;tr&gt;(内容为&lt;th&gt;) */</span></span><br><span class="line">Item Title</span><br><span class="line">&lt;/th&gt;&lt;th&gt;</span><br><span class="line">Description</span><br><span class="line">&lt;/th&gt;&lt;th&gt;</span><br><span class="line">Cost</span><br><span class="line">&lt;/th&gt;&lt;th&gt;</span><br><span class="line">Image</span><br><span class="line">&lt;/th&gt;&lt;/tr&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;tr <span class="class"><span class="keyword">class</span>=</span><span class="string">&quot;gift&quot;</span> id=<span class="string">&quot;gift1&quot;</span>&gt;&lt;td&gt; <span class="comment">/* 打印&lt;tr&gt;(内容为&lt;td&gt;) */</span></span><br><span class="line">Vegetable Basket</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">This vegetable basket is the perfect gift <span class="keyword">for</span> your health conscious (<span class="keyword">or</span> overweight) friends!</span><br><span class="line">&lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;Now with super-colorful bell peppers!&lt;/span&gt;</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">$<span class="number">15.00</span></span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img1.jpg&quot;</span>/&gt;</span><br><span class="line">&lt;/td&gt;&lt;/tr&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;tr class=<span class="string">&quot;gift&quot;</span> id=<span class="string">&quot;gift2&quot;</span>&gt;&lt;td&gt;</span><br><span class="line">Russian Nesting Dolls</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">Hand-painted by trained monkeys, these exquisite dolls are priceless! And by <span class="string">&quot;priceless,&quot;</span> we mean <span class="string">&quot;extremely expensive&quot;</span>! &lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;<span class="number">8</span> entire dolls per <span class="built_in">set</span>! Octuple the presents!&lt;/span&gt;</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">$<span class="number">10</span>,<span class="number">000.52</span></span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img2.jpg&quot;</span>/&gt;</span><br><span class="line">&lt;/td&gt;&lt;/tr&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;tr class=<span class="string">&quot;gift&quot;</span> id=<span class="string">&quot;gift3&quot;</span>&gt;&lt;td&gt;</span><br><span class="line">Fish Painting</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">If something seems fishy about <span class="keyword">this</span> painting, it<span class="number">&#x27;</span>s because it<span class="number">&#x27;</span>s a fish! &lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;Also hand-painted by trained monkeys!&lt;/span&gt;</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">$<span class="number">10</span>,<span class="number">005.00</span></span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img3.jpg&quot;</span>/&gt;</span><br><span class="line">&lt;/td&gt;&lt;/tr&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;tr class=<span class="string">&quot;gift&quot;</span> id=<span class="string">&quot;gift4&quot;</span>&gt;&lt;td&gt;</span><br><span class="line">Dead Parrot</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">This is an ex-parrot! &lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;Or maybe he<span class="number">&#x27;</span>s only resting?&lt;/span&gt;</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">$<span class="number">0.50</span></span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img4.jpg&quot;</span>/&gt;</span><br><span class="line">&lt;/td&gt;&lt;/tr&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;tr class=<span class="string">&quot;gift&quot;</span> id=<span class="string">&quot;gift5&quot;</span>&gt;&lt;td&gt;</span><br><span class="line">Mystery Box</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">If you love suprises, <span class="keyword">this</span> mystery box is <span class="keyword">for</span> you! Do <span class="keyword">not</span> place on light-colored surfaces. May cause oil staining. &lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;Keep your friends guessing!&lt;/span&gt;</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">$<span class="number">1.50</span></span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img6.jpg&quot;</span>/&gt;</span><br><span class="line">&lt;/td&gt;&lt;/tr&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">进程已结束，退出代码 <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>直观来看，下图中的标签就是“giftList”的子标签，程序就打印了对应几个 <code>&lt;tr&gt;</code> 框架</p>
<img src="/2022/04/02/Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/1648690984152.png" class width="1648690984152"> 
<p><strong>采用 .descendants，则可以打印所有后代标签</strong></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line">from bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">html = urlopen(<span class="string">&quot;http://www.pythonscraping.com/pages/page3.html&quot;</span>)</span><br><span class="line">bsObj = BeautifulSoup(html,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> child in bsObj.find(<span class="string">&quot;table&quot;</span>,&#123;<span class="string">&quot;id&quot;</span>:<span class="string">&quot;giftList&quot;</span>&#125;).descendants:</span><br><span class="line">    print(child)</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\ywx813\anaconda3\python.exe D:/PythonProject/Crawler/test.py</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;tr&gt;&lt;th&gt; <span class="comment">/* 打印&lt;tr&gt; */</span></span><br><span class="line">Item Title</span><br><span class="line">&lt;/th&gt;&lt;th&gt;</span><br><span class="line">Description</span><br><span class="line">&lt;/th&gt;&lt;th&gt;</span><br><span class="line">Cost</span><br><span class="line">&lt;/th&gt;&lt;th&gt;</span><br><span class="line">Image</span><br><span class="line">&lt;/th&gt;&lt;/tr&gt;</span><br><span class="line">&lt;th&gt; <span class="comment">/* 打印&lt;th&gt; */</span></span><br><span class="line">Item Title</span><br><span class="line">&lt;/th&gt;</span><br><span class="line"></span><br><span class="line">Item Title <span class="comment">/* 打印&lt;th&gt;框架中的内容 */</span></span><br><span class="line"></span><br><span class="line">&lt;th&gt;</span><br><span class="line">Description</span><br><span class="line">&lt;/th&gt;</span><br><span class="line"></span><br><span class="line">Description </span><br><span class="line"></span><br><span class="line">&lt;th&gt;</span><br><span class="line">Cost</span><br><span class="line">&lt;/th&gt;</span><br><span class="line"></span><br><span class="line">Cost </span><br><span class="line"></span><br><span class="line">&lt;th&gt;</span><br><span class="line">Image</span><br><span class="line">&lt;/th&gt;</span><br><span class="line"></span><br><span class="line">Image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;tr <span class="class"><span class="keyword">class</span>=</span><span class="string">&quot;gift&quot;</span> id=<span class="string">&quot;gift1&quot;</span>&gt;&lt;td&gt; <span class="comment">/* 打印&lt;tr&gt; */</span></span><br><span class="line">Vegetable Basket</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">This vegetable basket is the perfect gift <span class="keyword">for</span> your health conscious (<span class="keyword">or</span> overweight) friends!</span><br><span class="line">&lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;Now with super-colorful bell peppers!&lt;/span&gt;</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">$<span class="number">15.00</span></span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img1.jpg&quot;</span>/&gt;</span><br><span class="line">&lt;/td&gt;&lt;/tr&gt;</span><br><span class="line">&lt;td&gt; <span class="comment">/* 打印&lt;td&gt; */</span></span><br><span class="line">Vegetable Basket</span><br><span class="line">&lt;/td&gt;</span><br><span class="line"></span><br><span class="line">Vegetable Basket <span class="comment">/* 打印&lt;td&gt;框架中的内容 */</span></span><br><span class="line"></span><br><span class="line">&lt;td&gt; <span class="comment">/* 打印&lt;td&gt; */</span></span><br><span class="line">This vegetable basket is the perfect gift <span class="keyword">for</span> your health conscious (<span class="keyword">or</span> overweight) friends!</span><br><span class="line">&lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;Now with super-colorful bell peppers!&lt;/span&gt;</span><br><span class="line">&lt;/td&gt;</span><br><span class="line"></span><br><span class="line">This vegetable basket is the perfect gift <span class="keyword">for</span> your health conscious (<span class="keyword">or</span> overweight) friends!  <span class="comment">/* 打印&lt;td&gt;框架中的内容 */</span></span><br><span class="line"></span><br><span class="line">&lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;Now with super-colorful bell peppers!&lt;/span&gt;</span><br><span class="line">Now with super-colorful bell peppers!</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;td&gt; <span class="comment">/* 打印&lt;td&gt; */</span></span><br><span class="line">$<span class="number">15.00</span> <span class="comment">/* 打印&lt;td&gt;框架中的内容 */</span></span><br><span class="line">&lt;/td&gt;</span><br><span class="line"></span><br><span class="line">$<span class="number">15.00</span></span><br><span class="line"></span><br><span class="line">&lt;td&gt;</span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img1.jpg&quot;</span>/&gt;</span><br><span class="line">&lt;/td&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img1.jpg&quot;</span>/&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;tr class=<span class="string">&quot;gift&quot;</span> id=<span class="string">&quot;gift2&quot;</span>&gt;&lt;td&gt;</span><br><span class="line">Russian Nesting Dolls</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">Hand-painted by trained monkeys, these exquisite dolls are priceless! And by <span class="string">&quot;priceless,&quot;</span> we mean <span class="string">&quot;extremely expensive&quot;</span>! &lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;<span class="number">8</span> entire dolls per <span class="built_in">set</span>! Octuple the presents!&lt;/span&gt;</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">$<span class="number">10</span>,<span class="number">000.52</span></span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img2.jpg&quot;</span>/&gt;</span><br><span class="line">&lt;/td&gt;&lt;/tr&gt;</span><br><span class="line">&lt;td&gt;</span><br><span class="line">Russian Nesting Dolls</span><br><span class="line">&lt;/td&gt;</span><br><span class="line"></span><br><span class="line">Russian Nesting Dolls</span><br><span class="line"></span><br><span class="line">&lt;td&gt;</span><br><span class="line">Hand-painted by trained monkeys, these exquisite dolls are priceless! And by <span class="string">&quot;priceless,&quot;</span> we mean <span class="string">&quot;extremely expensive&quot;</span>! &lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;<span class="number">8</span> entire dolls per <span class="built_in">set</span>! Octuple the presents!&lt;/span&gt;</span><br><span class="line">&lt;/td&gt;</span><br><span class="line"></span><br><span class="line">Hand-painted by trained monkeys, these exquisite dolls are priceless! And by <span class="string">&quot;priceless,&quot;</span> we mean <span class="string">&quot;extremely expensive&quot;</span>! </span><br><span class="line">&lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;<span class="number">8</span> entire dolls per <span class="built_in">set</span>! Octuple the presents!&lt;/span&gt;</span><br><span class="line"><span class="number">8</span> entire dolls per <span class="built_in">set</span>! Octuple the presents!</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;td&gt;</span><br><span class="line">$<span class="number">10</span>,<span class="number">000.52</span></span><br><span class="line">&lt;/td&gt;</span><br><span class="line"></span><br><span class="line">$<span class="number">10</span>,<span class="number">000.52</span></span><br><span class="line"></span><br><span class="line">&lt;td&gt;</span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img2.jpg&quot;</span>/&gt;</span><br><span class="line">&lt;/td&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img2.jpg&quot;</span>/&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;tr class=<span class="string">&quot;gift&quot;</span> id=<span class="string">&quot;gift3&quot;</span>&gt;&lt;td&gt;</span><br><span class="line">Fish Painting</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">If something seems fishy about <span class="keyword">this</span> painting, it<span class="number">&#x27;</span>s because it<span class="number">&#x27;</span>s a fish! &lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;Also hand-painted by trained monkeys!&lt;/span&gt;</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">$<span class="number">10</span>,<span class="number">005.00</span></span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img3.jpg&quot;</span>/&gt;</span><br><span class="line">&lt;/td&gt;&lt;/tr&gt;</span><br><span class="line">&lt;td&gt;</span><br><span class="line">Fish Painting</span><br><span class="line">&lt;/td&gt;</span><br><span class="line"></span><br><span class="line">Fish Painting</span><br><span class="line"></span><br><span class="line">&lt;td&gt;</span><br><span class="line">If something seems fishy about <span class="keyword">this</span> painting, it<span class="number">&#x27;</span>s because it<span class="number">&#x27;</span>s a fish! &lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;Also hand-painted by trained monkeys!&lt;/span&gt;</span><br><span class="line">&lt;/td&gt;</span><br><span class="line"></span><br><span class="line">If something seems fishy about <span class="keyword">this</span> painting, it<span class="number">&#x27;</span>s because it<span class="number">&#x27;</span>s a fish! </span><br><span class="line">&lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;Also hand-painted by trained monkeys!&lt;/span&gt;</span><br><span class="line">Also hand-painted by trained monkeys!</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;td&gt;</span><br><span class="line">$<span class="number">10</span>,<span class="number">005.00</span></span><br><span class="line">&lt;/td&gt;</span><br><span class="line"></span><br><span class="line">$<span class="number">10</span>,<span class="number">005.00</span></span><br><span class="line"></span><br><span class="line">&lt;td&gt;</span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img3.jpg&quot;</span>/&gt;</span><br><span class="line">&lt;/td&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img3.jpg&quot;</span>/&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;tr class=<span class="string">&quot;gift&quot;</span> id=<span class="string">&quot;gift4&quot;</span>&gt;&lt;td&gt;</span><br><span class="line">Dead Parrot</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">This is an ex-parrot! &lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;Or maybe he<span class="number">&#x27;</span>s only resting?&lt;/span&gt;</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">$<span class="number">0.50</span></span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img4.jpg&quot;</span>/&gt;</span><br><span class="line">&lt;/td&gt;&lt;/tr&gt;</span><br><span class="line">&lt;td&gt;</span><br><span class="line">Dead Parrot</span><br><span class="line">&lt;/td&gt;</span><br><span class="line"></span><br><span class="line">Dead Parrot</span><br><span class="line"></span><br><span class="line">&lt;td&gt;</span><br><span class="line">This is an ex-parrot! &lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;Or maybe he<span class="number">&#x27;</span>s only resting?&lt;/span&gt;</span><br><span class="line">&lt;/td&gt;</span><br><span class="line"></span><br><span class="line">This is an ex-parrot! </span><br><span class="line">&lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;Or maybe he<span class="number">&#x27;</span>s only resting?&lt;/span&gt;</span><br><span class="line">Or maybe he<span class="number">&#x27;</span>s only resting?</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;td&gt;</span><br><span class="line">$<span class="number">0.50</span></span><br><span class="line">&lt;/td&gt;</span><br><span class="line"></span><br><span class="line">$<span class="number">0.50</span></span><br><span class="line"></span><br><span class="line">&lt;td&gt;</span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img4.jpg&quot;</span>/&gt;</span><br><span class="line">&lt;/td&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img4.jpg&quot;</span>/&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;tr class=<span class="string">&quot;gift&quot;</span> id=<span class="string">&quot;gift5&quot;</span>&gt;&lt;td&gt;</span><br><span class="line">Mystery Box</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">If you love suprises, <span class="keyword">this</span> mystery box is <span class="keyword">for</span> you! Do <span class="keyword">not</span> place on light-colored surfaces. May cause oil staining. &lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;Keep your friends guessing!&lt;/span&gt;</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">$<span class="number">1.50</span></span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img6.jpg&quot;</span>/&gt;</span><br><span class="line">&lt;/td&gt;&lt;/tr&gt;</span><br><span class="line">&lt;td&gt;</span><br><span class="line">Mystery Box</span><br><span class="line">&lt;/td&gt;</span><br><span class="line"></span><br><span class="line">Mystery Box</span><br><span class="line"></span><br><span class="line">&lt;td&gt;</span><br><span class="line">If you love suprises, <span class="keyword">this</span> mystery box is <span class="keyword">for</span> you! Do <span class="keyword">not</span> place on light-colored surfaces. May cause oil staining. &lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;Keep your friends guessing!&lt;/span&gt;</span><br><span class="line">&lt;/td&gt;</span><br><span class="line"></span><br><span class="line">If you love suprises, <span class="keyword">this</span> mystery box is <span class="keyword">for</span> you! Do <span class="keyword">not</span> place on light-colored surfaces. May cause oil staining. </span><br><span class="line">&lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;Keep your friends guessing!&lt;/span&gt;</span><br><span class="line">Keep your friends guessing!</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;td&gt;</span><br><span class="line">$<span class="number">1.50</span></span><br><span class="line">&lt;/td&gt;</span><br><span class="line"></span><br><span class="line">$<span class="number">1.50</span></span><br><span class="line"></span><br><span class="line">&lt;td&gt;</span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img6.jpg&quot;</span>/&gt;</span><br><span class="line">&lt;/td&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img6.jpg&quot;</span>/&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">进程已结束，退出代码 <span class="number">0</span></span><br></pre></td></tr></table></figure>
<img src="/2022/04/02/Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/1648691319757.png" class width="1648691319757"> 
<p>可以发现，程序不仅打印了对应几个 <code>&lt;tr&gt;</code> 框架，并且把其后代标签的框架与内容也打印了出来</p>
<p><strong>处理兄弟标签</strong></p>
<p>BeautifulSoup 的 next_siblings() 函数可以让收集表格数据成为简单的事情，尤其是处理带标题行的表格： </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">html = urlopen(<span class="string">&quot;http://www.pythonscraping.com/pages/page3.html&quot;</span>)</span><br><span class="line">bsObj = BeautifulSoup(html,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> sibling <span class="keyword">in</span> bsObj.find(<span class="string">&quot;table&quot;</span>,&#123;<span class="string">&quot;id&quot;</span>:<span class="string">&quot;giftList&quot;</span>&#125;).tr.next_siblings:</span><br><span class="line">    <span class="built_in">print</span>(sibling)</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\ywx813\anaconda3\python.exe D:/PythonProject/Crawler/test.py</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;tr <span class="class"><span class="keyword">class</span>=</span><span class="string">&quot;gift&quot;</span> id=<span class="string">&quot;gift1&quot;</span>&gt;&lt;td&gt;</span><br><span class="line">Vegetable Basket</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">This vegetable basket is the perfect gift <span class="keyword">for</span> your health conscious (<span class="keyword">or</span> overweight) friends!</span><br><span class="line">&lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;Now with super-colorful bell peppers!&lt;/span&gt;</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">$<span class="number">15.00</span></span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img1.jpg&quot;</span>/&gt;</span><br><span class="line">&lt;/td&gt;&lt;/tr&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;tr class=<span class="string">&quot;gift&quot;</span> id=<span class="string">&quot;gift2&quot;</span>&gt;&lt;td&gt;</span><br><span class="line">Russian Nesting Dolls</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">Hand-painted by trained monkeys, these exquisite dolls are priceless! And by <span class="string">&quot;priceless,&quot;</span> we mean <span class="string">&quot;extremely expensive&quot;</span>! &lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;<span class="number">8</span> entire dolls per <span class="built_in">set</span>! Octuple the presents!&lt;/span&gt;</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">$<span class="number">10</span>,<span class="number">000.52</span></span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img2.jpg&quot;</span>/&gt;</span><br><span class="line">&lt;/td&gt;&lt;/tr&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;tr class=<span class="string">&quot;gift&quot;</span> id=<span class="string">&quot;gift3&quot;</span>&gt;&lt;td&gt;</span><br><span class="line">Fish Painting</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">If something seems fishy about <span class="keyword">this</span> painting, it<span class="number">&#x27;</span>s because it<span class="number">&#x27;</span>s a fish! &lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;Also hand-painted by trained monkeys!&lt;/span&gt;</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">$<span class="number">10</span>,<span class="number">005.00</span></span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img3.jpg&quot;</span>/&gt;</span><br><span class="line">&lt;/td&gt;&lt;/tr&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;tr class=<span class="string">&quot;gift&quot;</span> id=<span class="string">&quot;gift4&quot;</span>&gt;&lt;td&gt;</span><br><span class="line">Dead Parrot</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">This is an ex-parrot! &lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;Or maybe he<span class="number">&#x27;</span>s only resting?&lt;/span&gt;</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">$<span class="number">0.50</span></span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img4.jpg&quot;</span>/&gt;</span><br><span class="line">&lt;/td&gt;&lt;/tr&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;tr class=<span class="string">&quot;gift&quot;</span> id=<span class="string">&quot;gift5&quot;</span>&gt;&lt;td&gt;</span><br><span class="line">Mystery Box</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">If you love suprises, <span class="keyword">this</span> mystery box is <span class="keyword">for</span> you! Do <span class="keyword">not</span> place on light-colored surfaces. May cause oil staining. &lt;span class=<span class="string">&quot;excitingNote&quot;</span>&gt;Keep your friends guessing!&lt;/span&gt;</span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">$<span class="number">1.50</span></span><br><span class="line">&lt;/td&gt;&lt;td&gt;</span><br><span class="line">&lt;img src=<span class="string">&quot;../img/gifts/img6.jpg&quot;</span>/&gt;</span><br><span class="line">&lt;/td&gt;&lt;/tr&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">进程已结束，退出代码 <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>这段代码会打印产品列表里的所有行的产品，第一行表格标题除外</p>
<ul>
<li>首先，对象不能把自己作为兄弟标签，任何时候你获取一个标签的兄弟标签，都不会包含这个标签本身 </li>
<li>其次，这个函数只调用后面的兄弟标签（例如，如果我们选择一组标签中位于中间位置的一个标签，然后用 next_siblings() 函数，那么它就只会返回在它后面的兄弟标签）</li>
</ul>
<p>因此，选择标签行然后调用 next_siblings，可以选择表格中除了标题行以外的所有行</p>
<p><strong>处理父标签</strong></p>
<p>在抓取网页的时候，查找父标签的需求比查找子标签和兄弟标签要少很多</p>
<p>通常情况 下，如果以抓取网页内容为目的来观察 HTML 页面，我们都是从最上层标签开始的，然 后思考如何定位我们想要的数据块所在的位置，但是，偶尔在特殊情况下你也会用到 BeautifulSoup 的父标签查找函数，parent 和 parents</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">html = urlopen(<span class="string">&quot;http://www.pythonscraping.com/pages/page3.html&quot;</span>)</span><br><span class="line">bsObj = BeautifulSoup(html,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(bsObj.find(<span class="string">&quot;img&quot;</span>,&#123;<span class="string">&quot;src&quot;</span>:<span class="string">&quot;../img/gifts/img1.jpg&quot;</span>&#125;).parent.previous_sibling.get_text())</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\ywx813\anaconda3\python.exe D:/PythonProject/Crawler/test.py</span><br><span class="line"></span><br><span class="line">$<span class="number">15.00</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">进程已结束，退出代码 <span class="number">0</span></span><br></pre></td></tr></table></figure>
<img src="/2022/04/02/Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/1648697579687.png" class width="1648697579687"> 
<p>这段代码会打印 ../img/gifts/img1.jpg 这个图片对应商品的价格（previousSibling属性返回：同一树层级中指定节点的前一个节点，刚好就是商品的价格）</p>
<h2 id="PS-正则表达式"><a href="#PS-正则表达式" class="headerlink" title="PS:正则表达式"></a>PS:正则表达式</h2><p>正则表达式，可以识别正则字符串（regular string），也就是说，它们可以这么定义：“如果你给我的字符串符合规则，我就返回它，或者是如果字符串不符合规则，我就忽略它”</p>
<p>正则表达式用于匹配一个符合规则的字符串，这在要求快速浏览大文档，以查找像电话号码和邮箱地址之类的字符串时是非常方便的</p>
<p>正则字符串，其实就是任意可以用一系列线性规则构成的字符串：</p>
<ul>
<li>字母“a”至少出现一次</li>
<li>后面跟着字母“b”重复 5 次</li>
<li>后面再跟字母“c”重复任意偶数次</li>
<li>最后一位是字母“d”，也可以没有</li>
</ul>
<p>满足上面规则的字符串有：“aaaabbbbbccccd”，“aabbbbbcc”等（有无穷多种变化），而正则表达式就是表达这组规则的缩写，这组规则的正则表达式如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aa*bbbbb(cc)*(d|)</span><br></pre></td></tr></table></figure>
<ul>
<li>aa<em> ：a 后面跟着的 `a</em>` 表示“重复任意次 a，包括 0 次”（意思就是a重复任意a次）</li>
<li>bbbbb ：这没有什么特别的（就是重复 5 次 b）</li>
<li>(cc)* ：任意偶数个字符都可以编组，这个规则是用括号两个 c，然后后面跟一个星号，表示有 任意次两个 c（也可以是 0 次） </li>
<li>(d|) ：增加一个竖线（|）在表达式里表示“或”，本例是表示：增加一个后面跟着“\x00”的 d，或者只有一个“\x00”（这样就可以保证字符串结尾为“d”或者“\x00”）</li>
</ul>
<p>常见的正则表达式：</p>
<ul>
<li><p>限定符</p>
<ul>
<li>?（问号）：表示符号前的字符需要出现0次或1次</li>
<li>*（星号）：表示符号前的字符可以出现0次或多次</li>
<li>+（加号）：表示符号前的字符可以出现1次或多次</li>
<li>{n,m}（花括号）：表示符号前面的字符需要出现n~m次</li>
<li>注意：当需要对多个字符进行操作时，可以先把字符括起来，然后在后面添加限定符</li>
</ul>
</li>
<li><p>或运算符</p>
<ul>
<li>a (n|m)：程序会先去匹配“a+空格”，然后要么匹配“n”，要么匹配“m”</li>
</ul>
</li>
<li><p>字符类</p>
<ul>
<li>[ … ]（方括号）：方括号中的内容可以很灵活，可以是单个字母，也可以用 “-” 来指定范围</li>
<li>^ （尖号，脱字符）：只能在方括号内部使用，表示把所写入的内容除外</li>
</ul>
</li>
<li><p>元字符</p>
<ul>
<li>\d ：代表数字字符（相当于[0 - 9]）</li>
<li>\w ：代表单词字符</li>
<li>\s ：代表空白字符（包括Tab字符，换行字符）</li>
<li>\D ：代表非数字字符（相当于[ ^ 0 - 9]）</li>
<li>\W ：代表非单词字符</li>
<li>\S ：代表非空白字符（包括Tab字符，换行字符）</li>
<li>.（句点）：代表不包含换行字符的任意字符</li>
<li>^ n：匹配行首的字符“n”</li>
<li>n $：匹配行尾的字符“n”</li>
</ul>
</li>
</ul>
<p>正则表达式中的贪婪匹配和懒惰匹配：</p>
<ul>
<li>贪婪匹配：“ * ”，“ + ”，“ {} ”，都是默认采用贪婪匹配，它们会尽可能多的匹配字符</li>
<li>懒惰匹配：如果在“ * ”，“ + ”，“ {} ”的后面加“ ? ”，就可以把它们切换为懒惰匹配，它们会尽可能少的匹配字符</li>
</ul>
<h2 id="通过正则表达式查找标签"><a href="#通过正则表达式查找标签" class="headerlink" title="通过正则表达式查找标签"></a>通过正则表达式查找标签</h2><p>在本例中，我们直接通过商品图片的文件路径来查找：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">html = urlopen(<span class="string">&quot;http://www.pythonscraping.com/pages/page3.html&quot;</span>)</span><br><span class="line">bsObj = BeautifulSoup(html,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line">images = bsObj.findAll(<span class="string">&quot;img&quot;</span>,&#123;<span class="string">&quot;src&quot;</span>:re.<span class="built_in">compile</span>(<span class="string">&quot;\.\.\/img\/gifts/img.*\.jpg&quot;</span>)&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> image <span class="keyword">in</span> images:</span><br><span class="line">    <span class="built_in">print</span>(image[<span class="string">&quot;src&quot;</span>])</span><br></pre></td></tr></table></figure>
<p>re.compile()，是用来优化正则的，它将正则表达式转化为对象</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\ywx813\anaconda3\python.exe D:/PythonProject/Crawler/test.py</span><br><span class="line">../img/gifts/img1.jpg</span><br><span class="line">../img/gifts/img2.jpg</span><br><span class="line">../img/gifts/img3.jpg</span><br><span class="line">../img/gifts/img4.jpg</span><br><span class="line">../img/gifts/img6.jpg</span><br><span class="line"></span><br><span class="line">进程已结束，退出代码 <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>现在解释一下这个正则表达式的内容：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.<span class="built_in">compile</span>(<span class="string">&quot;\.\.\/img\/gifts/img.*\.jpg&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>首先用转义符号索引两个“ . ”，然后用转义符号索引“/img”，“/gifts”，“/img”（其实这里的转义符号可以不加，因为“/”没有什么特殊含义），“ .* ”代表任意字符出现0次或者多次（这里改成“+”也没有什么问题），最后索引“.jpg”</p>
<h2 id="获取标签的属性"><a href="#获取标签的属性" class="headerlink" title="获取标签的属性"></a>获取标签的属性</h2><p>在网络数据采集时你经常不需要查找标签的内容，而是需要查找标签属性，对于一个标签对象，可以用下面的代码获取它的全部属性：（要注意这行代码返回的是一个 Python 字典对象，可以获取和操作这些属性）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">myTag.attrs</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">html = urlopen(<span class="string">&quot;http://www.pythonscraping.com/pages/page3.html&quot;</span>)</span><br><span class="line">bsObj = BeautifulSoup(html,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(bsObj.img.attrs)</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\ywx813\anaconda3\python.exe D:/PythonProject/Crawler/test.py</span><br><span class="line">&#123;<span class="string">&#x27;src&#x27;</span>: <span class="string">&#x27;../img/gifts/logo.jpg&#x27;</span>, <span class="string">&#x27;style&#x27;</span>: <span class="string">&#x27;float:left;&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">进程已结束，退出代码 <span class="number">0</span></span><br></pre></td></tr></table></figure>
<img src="/2022/04/02/Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/1648709275191.png" class width="1648709275191">  
<p>要获取图片的资源位置 src，可以用下面这行代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">myImgTag.attrs[<span class="string">&quot;src&quot;</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">html = urlopen(<span class="string">&quot;http://www.pythonscraping.com/pages/page3.html&quot;</span>)</span><br><span class="line">bsObj = BeautifulSoup(html,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(bsObj.img.attrs[<span class="string">&quot;src&quot;</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\ywx813\anaconda3\python.exe D:/PythonProject/Crawler/test.py</span><br><span class="line">../img/gifts/logo.jpg</span><br><span class="line"></span><br><span class="line">进程已结束，退出代码 <span class="number">0</span></span><br></pre></td></tr></table></figure>
<h2 id="遍历单个域名"><a href="#遍历单个域名" class="headerlink" title="遍历单个域名"></a>遍历单个域名</h2><p>我们需要先进行一个游戏：维基百科六度分隔理论，是把两个不相干的主题用一个总数不超过六条的主题连接起来</p>
<p>我们将创建一个项目来实现“维基百科六度分隔理论”的查找方法，要实现从 埃里克· 艾德尔 的词条页面（<code>https://en.wikipedia.org/wiki/Eric_Idle</code>）开始，经过最少的链接点击次数找到 凯文· 贝肯 的词条页面（<code>https://en.wikipedia.org/wiki/Kevin_Bacon</code>）</p>
<p>首先进行页面分析：</p>
<img src="/2022/04/02/Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/1648801080593.png" class width="1648801080593"> 
<p>鼠标移动到某个词条页面上时，对应的 HTML 代码会高亮，由此可以大致锁定词条页面对应的 HTML 标签（<code>&lt;a&gt;</code>），可以用以下代码来收集所有的 <code>&lt;a&gt;</code> 标签：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">html = urlopen(<span class="string">&quot;http://en.wikipedia.org/wiki/Kevin_Bacon&quot;</span>)</span><br><span class="line">bsObj = BeautifulSoup(html, <span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> bsObj.findAll(<span class="string">&quot;a&quot;</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;href&#x27;</span> <span class="keyword">in</span> link.attrs:</span><br><span class="line">        <span class="built_in">print</span>(link.attrs[<span class="string">&#x27;href&#x27;</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\ywx813\anaconda3\python.exe D:/PythonProject/Crawler/test.py</span><br><span class="line">/wiki/Wikipedia:Protection_policy<span class="comment">#semi</span></span><br><span class="line"><span class="comment">#mw-head</span></span><br><span class="line"><span class="comment">#searchInput</span></span><br><span class="line">/wiki/Kevin_Bacon_(disambiguation)</span><br><span class="line">/wiki/File:Kevin_Bacon_SDCC_2014.jpg</span><br><span class="line">/wiki/Philadelphia,_Pennsylvania</span><br><span class="line">/wiki/Kevin_Bacon_filmography</span><br><span class="line">/wiki/Kyra_Sedgwick</span><br><span class="line">/wiki/Sosie_Bacon</span><br><span class="line"><span class="comment">#cite_note-1</span></span><br><span class="line">/wiki/Edmund_Bacon_(architect)</span><br><span class="line">/wiki/Michael_Bacon_(musician)</span><br><span class="line">    </span><br><span class="line">.................................</span><br><span class="line">    </span><br><span class="line">//foundation.wikimedia.org/wiki/Terms_of_Use</span><br><span class="line">//foundation.wikimedia.org/wiki/Privacy_policy</span><br><span class="line">//www.wikimediafoundation.org/</span><br><span class="line">https://foundation.wikimedia.org/wiki/Privacy_policy</span><br><span class="line">/wiki/Wikipedia:About</span><br><span class="line">/wiki/Wikipedia:General_disclaimer</span><br><span class="line">//en.wikipedia.org/wiki/Wikipedia:Contact_us</span><br><span class="line">//en.m.wikipedia.org/w/index.php?title=Kevin_Bacon&amp;mobileaction=toggle_view_mobile</span><br><span class="line">https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute</span><br><span class="line">https://stats.wikimedia.org/<span class="comment">#/en.wikipedia.org</span></span><br><span class="line">https://foundation.wikimedia.org/wiki/Cookie_statement</span><br><span class="line">https://wikimediafoundation.org/</span><br><span class="line">https://www.mediawiki.org/</span><br><span class="line"></span><br><span class="line">进程已结束，退出代码 <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>发现有一些条目不是我们需要的内容（这里只展示部分），现在要近一步对样本进行分析：</p>
<p>首先需要比较“词条链接”和“其他链接”的差异，发现“词条链接”有3个共同点：</p>
<ul>
<li>它们都在 id 是 bodyContent 的 div 标签里（利用 find 嵌套可以解决）</li>
<li>URL 链接不包含分号（用正则解决）</li>
<li>URL 链接都以 /wiki/ 开头（用正则解决）</li>
</ul>
<p>改进爬虫脚本：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">html = urlopen(<span class="string">&quot;http://en.wikipedia.org/wiki/Kevin_Bacon&quot;</span>)</span><br><span class="line">bsObj = BeautifulSoup(html, <span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> bsObj.find(<span class="string">&quot;div&quot;</span>, &#123;<span class="string">&quot;id&quot;</span>:<span class="string">&quot;bodyContent&quot;</span>&#125;).findAll(<span class="string">&quot;a&quot;</span>,href=re.<span class="built_in">compile</span>(<span class="string">&quot;^(/wiki/)((?!:).)*$&quot;</span>)):</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;href&#x27;</span> <span class="keyword">in</span> link.attrs:</span><br><span class="line">        <span class="built_in">print</span>(link.attrs[<span class="string">&#x27;href&#x27;</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\ywx813\anaconda3\python.exe D:/PythonProject/Crawler/test.py</span><br><span class="line">/wiki/Kevin_Bacon_(disambiguation)</span><br><span class="line">/wiki/Philadelphia,_Pennsylvania</span><br><span class="line">/wiki/Kevin_Bacon_filmography</span><br><span class="line">/wiki/Kyra_Sedgwick</span><br><span class="line">/wiki/Sosie_Bacon</span><br><span class="line">/wiki/Edmund_Bacon_(architect)</span><br><span class="line"></span><br><span class="line">.................................</span><br></pre></td></tr></table></figure>
<p>如果你运行代码，就会看到维基百科上 凯文·贝肯 词条里所有指向其他词条的链接，但是现在找到的所有词条链接都是静态的模式，我们需要对其进行修改：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">nowTime=time.time()</span><br><span class="line">random.seed(nowTime)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getlinks</span>(<span class="params">articleUrl</span>):</span></span><br><span class="line">    html = urlopen(<span class="string">&quot;http://en.wikipedia.org&quot;</span>+articleUrl)</span><br><span class="line">    bsObj = BeautifulSoup(html,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> bsObj.find(<span class="string">&quot;div&quot;</span>,&#123;<span class="string">&quot;id&quot;</span>:<span class="string">&quot;bodyContent&quot;</span>&#125;).findAll(<span class="string">&quot;a&quot;</span>,href=re.<span class="built_in">compile</span>(<span class="string">&quot;^(/wiki/)((?!:).)*$&quot;</span>))</span><br><span class="line"></span><br><span class="line">links = getlinks(<span class="string">&quot;/wiki/Kevin_Bacon&quot;</span>)</span><br><span class="line"><span class="keyword">while</span> <span class="built_in">len</span>(links) &gt; <span class="number">0</span>:</span><br><span class="line">    newArticle = links[random.randint(<span class="number">0</span> ,<span class="built_in">len</span>(links)-<span class="number">1</span>)].attrs[<span class="string">&quot;href&quot;</span>]</span><br><span class="line">    <span class="built_in">print</span>(newArticle)</span><br><span class="line">    links = getlinks(newArticle)</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\ywx813\anaconda3\python.exe D:/PythonProject/Crawler/test.py</span><br><span class="line">/wiki/Seattle_International_Film_Festival</span><br><span class="line">/wiki/Bernardo_Bertolucci</span><br><span class="line">/wiki/The_Dreamers_(<span class="number">2003</span>_film)</span><br><span class="line">/wiki/Classical_Hollywood</span><br><span class="line">/wiki/Make-Up_Artists_and_Hair_Stylists_Guild_Awards</span><br></pre></td></tr></table></figure>
<p>程序的逻辑就是，先爬取某个词条里所有指向其他词条的链接，然后用随机数再次打开其中一个链接，重复进行此操作</p>
<p>为了完成“维基百科六度分隔理论”，还需要对收集词条链接的数据进行分析，那就是后话了</p>
<h2 id="采集整个网站"><a href="#采集整个网站" class="headerlink" title="采集整个网站"></a>采集整个网站</h2><p>遍历整个网站的网络数据是一件费时费力的事情，但是采集它们有许多好处</p>
<p>一个简单的方法就是：从顶级页面开始（比如主页），然后搜索页面上的所有链接，形成列表，再去采集这些链接的每一个页面，然后把在每个页面上找到的链接形成新的列表，重复执行下一轮采集</p>
<p>很明显，这是一个复杂度增长很快的情形，为了避免一个页面被采集两次，链接去重是非常重要的，在代码运行时，把已发现的所有链接都放到一起，并保存在方便查询的列表里，只有“新”链接才会被采集，之后再从页面中搜索其他链接：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">pages = <span class="built_in">set</span>()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getLinks</span>(<span class="params">pageUrl</span>):</span></span><br><span class="line">    <span class="keyword">global</span> pages</span><br><span class="line">    html = urlopen(<span class="string">&quot;http://en.wikipedia.org&quot;</span>+pageUrl)</span><br><span class="line">    bsObj = BeautifulSoup(html,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> link <span class="keyword">in</span> bsObj.findAll(<span class="string">&quot;a&quot;</span>, href=re.<span class="built_in">compile</span>(<span class="string">&quot;^(/wiki/)&quot;</span>)):</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;href&#x27;</span> <span class="keyword">in</span> link.attrs:</span><br><span class="line">            <span class="keyword">if</span> link.attrs[<span class="string">&#x27;href&#x27;</span>] <span class="keyword">not</span> <span class="keyword">in</span> pages:</span><br><span class="line">                newPage = link.attrs[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">                <span class="built_in">print</span>(newPage)</span><br><span class="line">                pages.add(newPage)</span><br><span class="line">                getLinks(newPage)</span><br><span class="line"></span><br><span class="line">getLinks(<span class="string">&quot;&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\ywx813\anaconda3\python.exe D:/PythonProject/Crawler/test.py</span><br><span class="line">/wiki/Wikipedia</span><br><span class="line">/wiki/Wikipedia:Protection_policy<span class="meta">#semi</span></span><br><span class="line">/wiki/Wikipedia:Requests_for_page_protection</span><br><span class="line">/wiki/Wikipedia:Requests_for_permissions</span><br><span class="line">/wiki/Wikipedia:Protection_policy<span class="meta">#extended</span></span><br></pre></td></tr></table></figure>
<p>这个爬虫只收集了词条链接的信息，当然也可以改进下，使其可以收集更多信息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">pages = <span class="built_in">set</span>()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getLinks</span>(<span class="params">pageUrl</span>):</span></span><br><span class="line">    <span class="keyword">global</span> pages</span><br><span class="line">    html = urlopen(<span class="string">&quot;http://en.wikipedia.org&quot;</span>+pageUrl)</span><br><span class="line">    bsObj = BeautifulSoup(html,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(bsObj.h1.get_text())</span><br><span class="line">        <span class="built_in">print</span>(bsObj.find(<span class="built_in">id</span>=<span class="string">&quot;mw-content-text&quot;</span>).findAll(<span class="string">&quot;p&quot;</span>)[<span class="number">0</span>])</span><br><span class="line">        <span class="built_in">print</span>(bsObj.find(<span class="built_in">id</span>=<span class="string">&quot;ca-edit&quot;</span>).find(<span class="string">&quot;span&quot;</span>).find(<span class="string">&quot;a&quot;</span>).attrs[<span class="string">&#x27;href&#x27;</span>])</span><br><span class="line">    <span class="keyword">except</span> AttributeError:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;The page is missing some properties! But don&#x27;t worry!&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> link <span class="keyword">in</span> bsObj.findAll(<span class="string">&quot;a&quot;</span>, href=re.<span class="built_in">compile</span>(<span class="string">&quot;^(/wiki/)&quot;</span>)):</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;href&#x27;</span> <span class="keyword">in</span> link.attrs:</span><br><span class="line">            <span class="keyword">if</span> link.attrs[<span class="string">&#x27;href&#x27;</span>] <span class="keyword">not</span> <span class="keyword">in</span> pages:</span><br><span class="line">                newPage = link.attrs[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">                <span class="built_in">print</span>(newPage)</span><br><span class="line">                pages.add(newPage)</span><br><span class="line">                getLinks(newPage)</span><br><span class="line"></span><br><span class="line">getLinks(<span class="string">&quot;&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>因为数据有点多并且没有什么价值，所以就不展示了</p>
<h2 id="通过互联网采集"><a href="#通过互联网采集" class="headerlink" title="通过互联网采集"></a>通过互联网采集</h2><p>就像之前的例子一样，我们后面要建立的网络爬虫也是顺着链接从一个页面跳到另一个页面，描绘出一张网络地图</p>
<p>但是这一次，它们不再忽略外链，而是跟着外链跳转，我们想看看爬虫是不是可以记录我们浏览过的每一个页面上的信息，这将是一个新的挑战</p>
<p>相比我们之前做的单个域名采集，互联网采集要难得多 —— 不同网站的布局迥然不同，这就意味着我们必须在要寻找的信息以及查找方式上都极具灵活性</p>
<ul>
<li>我要收集哪些数据？这些数据可以通过采集几个已经确定的网站（永远是最简单的做法）完成吗？或者我的爬虫需要发现那些我可能不知道的网站吗？</li>
<li>当我的爬虫到了某个网站，它是立即顺着下一个出站链接跳到一个新网站，还是在网站上呆一会儿，深入采集网站的内容？</li>
<li>有没有我不想采集的一类网站？我对非英文网站的内容感兴趣吗？</li>
<li>如果我的网络爬虫引起了某个网站网管的怀疑，我如何避免法律责任？</li>
</ul>
<p>先看一个案例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">pages = <span class="built_in">set</span>()</span><br><span class="line">nowTime = time.time()</span><br><span class="line">random.seed(nowTime)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getInternalLinks</span>(<span class="params">bsObj, includeUrl</span>):</span> <span class="comment"># 获取页面所有内链的列表</span></span><br><span class="line">    internalLinks = []</span><br><span class="line">    <span class="keyword">for</span> link <span class="keyword">in</span> bsObj.findAll(<span class="string">&quot;a&quot;</span>, href=re.<span class="built_in">compile</span>(<span class="string">&quot;^(/|.*&quot;</span>+includeUrl+<span class="string">&quot;)&quot;</span>)):</span><br><span class="line">        <span class="keyword">if</span> link.attrs[<span class="string">&#x27;href&#x27;</span>] <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> link.attrs[<span class="string">&#x27;href&#x27;</span>] <span class="keyword">not</span> <span class="keyword">in</span> internalLinks:</span><br><span class="line">                internalLinks.append(link.attrs[<span class="string">&#x27;href&#x27;</span>])</span><br><span class="line">                <span class="keyword">return</span> internalLinks</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getExternalLinks</span>(<span class="params">bsObj, excludeUrl</span>):</span> <span class="comment"># 获取页面所有外链的列表</span></span><br><span class="line">    externalLinks = []</span><br><span class="line">    <span class="keyword">for</span> link <span class="keyword">in</span> bsObj.findAll(<span class="string">&quot;a&quot;</span>,href=re.<span class="built_in">compile</span>(<span class="string">&quot;^(http|www)((?!&quot;</span>+excludeUrl+<span class="string">&quot;).)*$&quot;</span>)):</span><br><span class="line">        <span class="keyword">if</span> link.attrs[<span class="string">&#x27;href&#x27;</span>] <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> link.attrs[<span class="string">&#x27;href&#x27;</span>] <span class="keyword">not</span> <span class="keyword">in</span> externalLinks:</span><br><span class="line">                externalLinks.append(link.attrs[<span class="string">&#x27;href&#x27;</span>])</span><br><span class="line">                <span class="keyword">return</span> externalLinks</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">splitAddress</span>(<span class="params">address</span>):</span> <span class="comment"># 加工静态链接</span></span><br><span class="line">    addressParts = address.replace(<span class="string">&quot;http://&quot;</span>, <span class="string">&quot;&quot;</span>).split(<span class="string">&quot;/&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> addressParts</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getRandomExternalLink</span>(<span class="params">startingPage</span>):</span> <span class="comment"># 从内&amp;外链列表中获取随机的外链</span></span><br><span class="line">    html = urlopen(startingPage)</span><br><span class="line">    bsObj = BeautifulSoup(html,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line">    externalLinks = getExternalLinks(bsObj, splitAddress(startingPage)[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(externalLinks) == <span class="number">0</span>:</span><br><span class="line">        internalLinks = getInternalLinks(startingPage)</span><br><span class="line">        <span class="keyword">return</span> getRandomExternalLink(internalLinks[random.randint(<span class="number">0</span>,<span class="built_in">len</span>(internalLinks)-<span class="number">1</span>)])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> externalLinks[random.randint(<span class="number">0</span>, <span class="built_in">len</span>(externalLinks)-<span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">followExternalOnly</span>(<span class="params">startingSite</span>):</span> <span class="comment"># 程序开始</span></span><br><span class="line">    externalLink = getRandomExternalLink(startingSite)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;随机外链是：&quot;</span>+externalLink)</span><br><span class="line">    followExternalOnly(externalLink)</span><br><span class="line"></span><br><span class="line">followExternalOnly(<span class="string">&quot;http://oreilly.com&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\ywx813\anaconda3\python.exe D:/PythonProject/Crawler/test.py</span><br><span class="line">随机外链是：https:<span class="comment">//twitter.com/oreillymedia</span></span><br><span class="line">随机外链是：https:<span class="comment">//help.twitter.com/using-twitter/twitter-supported-browsers</span></span><br><span class="line">随机外链是：https:<span class="comment">//microsoft.com/edge</span></span><br></pre></td></tr></table></figure>
<p>网站首页上并不能保证一直能发现外链，这时为了能够发现外链，就需要用一种类似前面案例中使用的采集方法，即递归地深入一个网站直到找到一个外链才停止</p>
<p>如果想要收集内&amp;外链，则可以加入以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">allExtLinks = <span class="built_in">set</span>()</span><br><span class="line">allIntLinks = <span class="built_in">set</span>()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getAllExternalLinks</span>(<span class="params">siteUrl</span>):</span></span><br><span class="line">    html = urlopen(siteUrl)</span><br><span class="line">    bsObj = BeautifulSoup(html)</span><br><span class="line">    internalLinks = getInternalLinks(bsObj,splitAddress(siteUrl)[<span class="number">0</span>])</span><br><span class="line">    externalLinks = getExternalLinks(bsObj,splitAddress(siteUrl)[<span class="number">0</span>])</span><br><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> externalLinks:</span><br><span class="line">    <span class="keyword">if</span> link <span class="keyword">not</span> <span class="keyword">in</span> allExtLinks:</span><br><span class="line">        allExtLinks.add(link)</span><br><span class="line">        <span class="built_in">print</span>(link)</span><br><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> internalLinks:</span><br><span class="line">    <span class="keyword">if</span> link <span class="keyword">not</span> <span class="keyword">in</span> allIntLinks:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;即将获取链接的URL是：&quot;</span>+link)</span><br><span class="line">        allIntLinks.add(link)</span><br><span class="line">        getAllExternalLinks(link)</span><br><span class="line">        </span><br><span class="line">getAllExternalLinks(<span class="string">&quot;http://oreilly.com&quot;</span>)</span><br></pre></td></tr></table></figure>
<img src="/2022/04/02/Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/1648810074420.png" class width="1648810074420"> 
<p>写代码之前拟个大纲或画个流程图是很好的编程习惯，这么做不仅可以为你后期处理节省很多时间，更重要的是可以防止自己在爬虫变得越来越复杂时乱了分寸</p>
<h2 id="通过Scrapy采集"><a href="#通过Scrapy采集" class="headerlink" title="通过Scrapy采集"></a>通过Scrapy采集</h2><p>Scrapy 就是一个帮你大幅度降低网页链接查找和识别工作复杂度的 Python 库，它可以 让你轻松地采集一个或多个域名的信息</p>
<p>首先在命令行输入：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$scrapy startproject wikiSpider</span><br></pre></td></tr></table></figure>
<p>系统就会自动帮你创建一个 Scrapy 爬虫模板，Scrapy 的每个 Item（条目）对象表示网站上的一个页面，当然，你可以根据需要定义不同的条目（比如 url、content、header image 等），但是现在我只演示收集每页的 title 字段 （field）</p>
<p>先在你的 items.py 文件中写入以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># Define here the models for your scraped items</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># See documentation in:</span></span><br><span class="line"><span class="comment"># http://doc.scrapy.org/en/latest/topics/items.html</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Item, Field</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Article</span>(<span class="params">Item</span>):</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line">    title = Field()</span><br></pre></td></tr></table></figure>
<p>然后在 spiders 目录中新建一个 articleSpider.py 文件，然后写入以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.selector <span class="keyword">import</span> Selector</span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Spider</span><br><span class="line"><span class="keyword">from</span> wikiSpider.items <span class="keyword">import</span> Article</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ArticleSpider</span>(<span class="params">Spider</span>):</span></span><br><span class="line">    name=<span class="string">&quot;article&quot;</span></span><br><span class="line">    allowed_domains = [<span class="string">&quot;en.wikipedia.org&quot;</span>]</span><br><span class="line">    start_urls = [<span class="string">&quot;http://en.wikipedia.org/wiki/Main_Page&quot;</span>,</span><br><span class="line"> <span class="string">&quot;http://en.wikipedia.org/wiki/Python_%28programming_language%29&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        item = Article()</span><br><span class="line">        title = response.xpath(<span class="string">&#x27;//h1/text()&#x27;</span>)[<span class="number">0</span>].extract()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Title is: &quot;</span>+title)</span><br><span class="line">        item[<span class="string">&#x27;title&#x27;</span>] = title</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>
<p>最后在 pycharm 的控制台中输入以下命令来执行爬虫：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy crawl article</span><br></pre></td></tr></table></figure>
<h2 id="PS-API"><a href="#PS-API" class="headerlink" title="PS:API"></a>PS:API</h2><p>API 为不同的应用提供了方便友好的接口，不同的开发者用不同的架构，甚至不同的语言编写软件都没问题 —— 因为 API 设计的目的就是要成为一种通用语言，让不同的软件进行信息共享</p>
<p>API 可以通过 HTTP 协议下载文件，和 URL 访问网站获取数据的协议一 样，它几乎可以实现所有在网上干的事情，API 之所以叫 API 而不是叫网站的原因，其实是首先 API 请求使用非常严谨的语法，其次 API 用 JSON 或 XML 格式表示数据，而不是 HTML 格式</p>
<p><strong>API通用规则:方法</strong></p>
<p>和大多数网络数据采集的方式不同，API 用一套非常标准的规则生成数据，而且生成的数据也是按照非常标准的方式组织的</p>
<p>利用 HTTP 从网络服务获取信息有四种方式：</p>
<ul>
<li>GET<ul>
<li>GET 就是你在浏览器中输入网址浏览网站所做的事情，当你访问某个网站时，就会使用 GET 方法（可以想象成 GET 在说：“喂，网络服务器，请按 照这个网址给我信息”）</li>
</ul>
</li>
<li>POST<ul>
<li>POST 基本就是当你填写表单或提交信息到网络服务器的后端程序时所做的事情，每次当你登录网站的时候，就是通过用户名和（有可能加密的）密码发起一个 POST 请求（如果你用 API 发起一个 POST 请求，相当于说“请把信息保存到你的数据库里”）</li>
</ul>
</li>
<li>PUT<ul>
<li>PUT 请求用来更新一个对象或信息（例如：API 可能会要求用 POST 请求来创建新用户，但是如果你要更新老用户的邮箱地址，就要用 PUT 请求了）</li>
</ul>
</li>
<li>DELETE<ul>
<li>用于删除一个对象</li>
</ul>
</li>
</ul>
<p><strong>API通用规则:验证</strong></p>
<p>虽然有些 API 不需要验证操作（就是说任何人都可以使用 API，不需要注册），但是很多新式 API 在使用之前都要求客户验证</p>
<p>通常 API 验证的方法都是用类似令牌（token）的方式调用，每次 API 调用都会把令牌传递到服务器上，这种令牌要么是用户注册的时候分配给用户，要么就是在用户调用的时候才提供，可能是长期固定的值，也可能是频繁变化的，通过服务器对用户名和密码的组合处理后生成 </p>
<p>令牌除了在 URL 链接中传递，还会通过请求头里的 cookie 把用户信息传递给服务器</p>

    </div>

    
    
    

      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/Crawler/" rel="tag"><i class="fa fa-tag"></i> Crawler</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/04/02/stdin%E4%BB%BB%E6%84%8F%E5%86%99/" rel="prev" title="Stdin任意写">
      <i class="fa fa-chevron-left"></i> Stdin任意写
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/04/03/Stdout%E4%BB%BB%E6%84%8F%E5%86%99+Stdout%E4%BB%BB%E6%84%8F%E8%AF%BB+%E6%A0%BC%E5%BC%8F%E5%8C%96%E6%BC%8F%E6%B4%9E%E4%B8%AD%E7%9A%84hook%E5%8A%AB%E6%8C%81/" rel="next" title="Stdout任意写+Stdout任意读+格式化漏洞中的hook劫持">
      Stdout任意写+Stdout任意读+格式化漏洞中的hook劫持 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Python%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86"><span class="nav-number">1.</span> <span class="nav-text">Python网络数据采集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%9D%E8%80%83%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E6%97%B6%E9%80%9A%E5%B8%B8%E7%9A%84%E6%83%B3%E6%B3%95"><span class="nav-number">2.</span> <span class="nav-text">思考网络爬虫时通常的想法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PS-MAC%E5%9C%B0%E5%9D%80"><span class="nav-number">3.</span> <span class="nav-text">PS:MAC地址</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PS-Cookie"><span class="nav-number">4.</span> <span class="nav-text">PS:Cookie</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PS-Session"><span class="nav-number">5.</span> <span class="nav-text">PS:Session</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PS-Token"><span class="nav-number">6.</span> <span class="nav-text">PS:Token</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E6%B5%8F%E8%A7%88%E5%99%A8-amp-%E7%88%AC%E8%99%AB%E5%8E%9F%E7%90%86"><span class="nav-number">7.</span> <span class="nav-text">网络浏览器&amp;爬虫原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BeautifulSoup%E7%AE%80%E4%BB%8B"><span class="nav-number">8.</span> <span class="nav-text">BeautifulSoup简介</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E2%80%9C%E5%8F%AF%E9%9D%A0%E2%80%9D%E7%9A%84%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5"><span class="nav-number">9.</span> <span class="nav-text">“可靠”的网络连接</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%80%9A%E8%BF%87%E5%B1%9E%E6%80%A7%E6%9F%A5%E6%89%BE%E6%A0%87%E7%AD%BE"><span class="nav-number">10.</span> <span class="nav-text">通过属性查找标签</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PS-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1"><span class="nav-number">11.</span> <span class="nav-text">PS:面向对象</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AF%BC%E8%88%AA%E6%A0%91"><span class="nav-number">12.</span> <span class="nav-text">导航树</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PS-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F"><span class="nav-number">13.</span> <span class="nav-text">PS:正则表达式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%80%9A%E8%BF%87%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%9F%A5%E6%89%BE%E6%A0%87%E7%AD%BE"><span class="nav-number">14.</span> <span class="nav-text">通过正则表达式查找标签</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%8E%B7%E5%8F%96%E6%A0%87%E7%AD%BE%E7%9A%84%E5%B1%9E%E6%80%A7"><span class="nav-number">15.</span> <span class="nav-text">获取标签的属性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%81%8D%E5%8E%86%E5%8D%95%E4%B8%AA%E5%9F%9F%E5%90%8D"><span class="nav-number">16.</span> <span class="nav-text">遍历单个域名</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%87%87%E9%9B%86%E6%95%B4%E4%B8%AA%E7%BD%91%E7%AB%99"><span class="nav-number">17.</span> <span class="nav-text">采集整个网站</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%80%9A%E8%BF%87%E4%BA%92%E8%81%94%E7%BD%91%E9%87%87%E9%9B%86"><span class="nav-number">18.</span> <span class="nav-text">通过互联网采集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%80%9A%E8%BF%87Scrapy%E9%87%87%E9%9B%86"><span class="nav-number">19.</span> <span class="nav-text">通过Scrapy采集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PS-API"><span class="nav-number">20.</span> <span class="nav-text">PS:API</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="yhellow"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">yhellow</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">147</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">103</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">yhellow</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="Symbols count total">1.9m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">28:53</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  

</body>
</html>
